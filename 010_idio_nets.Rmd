---
title: "010_idio_nets"
author: "Sglatt"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages
```{r packages}
if (!require("dplyr")) {
  install.packages("dplyr")
  require("dplyr")
}
if (!require("lubridate")) {
  install.packages("lubridate")
  require("lubridate")
}
if (!require("purrr")) {
  install.packages("purrr")
  require("purrr")
}
if (!require("tidyr")) {
  install.packages("tidyr")
  require("tidyr")
}
if (!require("qgraph")) {
  install.packages("qgraph")
  require("qgraph")
}
if (!require("graphicalVAR")) {
  install.packages("graphicalVAR")
  require("graphicalVAR")
}
if (!require("ggplot2")) {
  install.packages("ggplot2")
  require("ggplot2")
}
if (!require("tibble")) {
  install.packages("tibble")
  require("tibble")
}
```

# Import the dataset
```{r data}
dataset <- read.csv("010_raw_materials/PT_EMA 2022-05-17 full cleaned with controls without _F.csv")
colnames(dataset)

# We will be using the symptoms:
# fowg = I am terrified of gaining weight.
# drivethin = I am preoccupied with the desire to be thinner.
# bodydiss = I do not like how my body looks.
# bodycheck = I frequently check to see if my body has changed (e.g., by pinching).
# heartrace = My heart races for no good reason.
# interocept = I am very sensitive to changes in my internal bodily sensations. (trust/mistrust in body sensations).
# pays_sens = I don't like the physical sensations I feel when eating. (trust/mistrust in body sensations).
# feelfat = I feel fat

# Filter the dataset to ID (IDclean), day/beep variables (dayvar, beepvar), and those symptoms
filtered_dataset <- dataset %>%
  select(
    IDclean, dayvar, beepvar,
    fowg, drivethin, bodydiss, bodycheck,
    heartrace, interocept, pays_sens, feelfat
  )

# How many people are in this dataset?
length(unique(filtered_dataset$IDclean)) # 128
```

# Look at missingness for each person for those six symptoms
```{r missing}
missing_per_id <- filtered_dataset %>%
  select(-dayvar, -beepvar) %>%
  group_by(IDclean) %>%
  summarise(
    total_vals = n() * 6,
    missing_vals = sum(is.na(c_across(fowg:pays_sens))),
    percent_missing = round((missing_vals / total_vals) * 100, 2)
  )

# This will show you the the total number of observations for each person and the  ~approximate % missing. >50% missing may not converge in analyses
missing_per_id
```

# Mean and SD for those six symptoms for each person
```{r m sd}
descriptives_per_id <- filtered_dataset %>%
  select(IDclean, fowg, drivethin, bodydiss, bodycheck, interocept, pays_sens) %>%
  group_by(IDclean) %>%
  summarise(
    fowg_mean = mean(fowg, na.rm = TRUE),
    fowg_sd = sd(fowg, na.rm = TRUE),
    drivethin_mean = mean(drivethin, na.rm = TRUE),
    drivethin_sd = sd(drivethin, na.rm = TRUE),
    bodydiss_mean = mean(bodydiss, na.rm = TRUE),
    bodydiss_sd = sd(bodydiss, na.rm = TRUE),
    bodycheck_mean = mean(bodycheck, na.rm = TRUE),
    bodycheck_sd = sd(bodycheck, na.rm = TRUE),
    interocept_mean = mean(interocept, na.rm = TRUE),
    interocept_sd = sd(interocept, na.rm = TRUE),
    pays_sens_mean = mean(pays_sens, na.rm = TRUE),
    pays_sens_sd = sd(pays_sens, na.rm = TRUE),
    .groups = "drop"
  )

# This will show you the mean and standrad deviation of every symptom for every person.
descriptives_per_id

# Now, we should check if anyone has symptoms with a standard deviation close to 0.
# standard deviations close to 0 can lead to convergence issues in the estimation of the network model

# Pulling the SD information from the descriptive's data frame
sd_data <- descriptives_per_id %>%
  select(IDclean, ends_with("_sd"))

# Changing that to long format
sd_long <- sd_data %>%
  pivot_longer(
    cols = ends_with("_sd"),
    names_to = "symptom",
    values_to = "sd"
  )

# Now, find the people-symptom pairs that have low SDs
low_sd <- sd_long %>%
  filter(sd < 5)

# This will show you the symptoms that have low SDs for each person
# For example, in the first row, PT004 has an SD of 2.53 for bodycheck and pays_sens
low_sd
```

# Check for people with >1 day-beep pair
```{r duplicate obs}
duplicates <- filtered_dataset %>%
  group_by(IDclean, dayvar, beepvar) %>%
  filter(n() > 1) %>%
  arrange(IDclean, dayvar, beepvar)

duplicates

# How many IDs have this problem?
length(unique(duplicates$IDclean)) # 15

# Who are they?
unique(duplicates$IDclean)
# "PT001" "PT006" "PT007" "PT012" "PT013" "PT015" "PT018" "PT019" "PT025" "PT029" "PT030" "PT035" "PT047" "PT048" "PT056"

# Exclude those IDs from the dataset
xclude_ids <- unique(duplicates$IDclean)

# Create a clean dataset without those participants
filtered_dataset_nodupes <- filtered_dataset %>%
  filter(!(IDclean %in% xclude_ids))
```

# Pick an ID for analysis
```{r ID}
# Get a list of all the IDs in the dataset
sort(unique(filtered_dataset_nodupes$IDclean))

id_name <- "PT003" # put the ID that you want to do analysis for
output_dir <- "C:/Users/Sofel/Box/Interoceptive Asbtract/Network_results" # put the location where you want the results to be saved

# Select the data for that ID
data_network <- filtered_dataset_nodupes %>%
  filter(IDclean == id_name) %>%
  select(-IDclean) # drop ID column

# Define the symptoms
variable_names <- c("fowg", "drivethin", "bodydiss", "bodycheck", "interocept", "pays_sens")
```

# Idiographic networks
```{r idio nets}
network <- graphicalVAR(
  data_network,
  vars = variable_names,
  dayvar = "dayvar",
  beepvar = "beepvar",
  gamma = 0,
  verbose = FALSE
)

# save graphs separately
# Contemporaneous network (PCC)
pdf(file = file.path(output_dir, paste0(id_name, "_network_PCC.pdf")), height = 5, width = 8)
pcc <- plot(network, "PCC",
  labels = variable_names,
  edge.labels = TRUE,
  layout = "spring",
  label.cex = 1.3,
  alpha = 0.05,
  vsize = 9
)
dev.off()

# Temporal network (PDC)
pdf(file = file.path(output_dir, paste0(id_name, "_network_PDC.pdf")), height = 5, width = 8)
pdc <- plot(network, "PDC",
  labels = variable_names,
  label.cex = 1.3,
  alpha = 0.05,
  vsize = 9,
  edge.labels = TRUE,
  repulsion = 1.5
)
dev.off()


# Create and save centrality plots
centralityplot <- plot(network,
  labels = variable_names,
  edge.labels = TRUE,
  layout = "spring"
) %>%
  centralityPlot() +
  theme(legend.position = "none") +
  theme(
    axis.text = element_text(size = 13),
    strip.text.y = element_text(size = 15),
    axis.text.x = element_text(angle = 90),
    strip.text.x = element_text(size = 15)
  )

ggsave(filename = file.path(output_dir, paste0(id_name, "_centralityplot.png")), plot = centralityplot)

# Centrality tables
# PCC centrality
pcc_cent <- centrality_auto(pcc)[[1]]$node.centrality %>%
  rownames_to_column("nodes") %>%
  mutate(type = "PCC") %>%
  relocate(type)

# PDC centrality
pdc_cent <- centrality_auto(pdc)[[1]]$node.centrality %>%
  rownames_to_column("nodes") %>%
  mutate(type = "PDC") %>%
  relocate(type)

# Combine and export
centr <- plyr::rbind.fill(pcc_cent, pdc_cent)
write.csv(centr, file.path(
  output_dir,
  paste0(id_name, "_centralitytables.csv")
),
row.names = FALSE
)

# Edge tables
# PCC edges
pcc_edges <- data.frame(pcc[[1]][[1]])
write.csv(pcc_edges, file.path(
  output_dir,
  paste0(id_name, "_pcc_edges.csv")
),
row.names = TRUE
)

# PDC edges
pdc_edges <- data.frame(pdc[[1]][[1]])
write.csv(pdc_edges, file.path(
  output_dir,
  paste0(id_name, "_pdc_edges.csv")
),
row.names = TRUE
)

# Save workspace
save.image(file = file.path(
  output_dir,
  paste0(id_name, ".RData")
))
```

